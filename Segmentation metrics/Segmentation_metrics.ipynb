{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ba78d4e-868e-47fd-8e22-07b6d33fe0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import initializers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import measure\n",
    "from scipy.spatial.distance import cdist\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf9804b-3d92-45ec-bbf4-8ee4f5f965ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from the .keras file\n",
    "model = load_model(r\"C:\\Users\\Mafe Valenzuela\\Documents\\Cps\\CÃ³digos\\model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c3cc919-845c-4109-94c5-5b85f486f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Define image dimensions\n",
    "IMG_HEIGHT = 176\n",
    "IMG_WIDTH = 320\n",
    "\n",
    "def load_images_and_masks_from_directory(validation_dir):\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    # Define folder paths\n",
    "    image_dir = os.path.join(validation_dir, 'images')\n",
    "    mask_dir = os.path.join(validation_dir, 'masks')\n",
    "\n",
    "    # Check if the folders exist\n",
    "    if not os.path.exists(image_dir):\n",
    "        print(f\"Error: Image folder not found at {image_dir}\")\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    if not os.path.exists(mask_dir):\n",
    "        print(f\"Error: Mask folder not found at {mask_dir}\")\n",
    "        return np.array([]), np.array([])\n",
    "        \n",
    "    # Get sorted image and mask filenames\n",
    "    image_files = sorted(os.listdir(image_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "    mask_files = sorted(os.listdir(mask_dir), key=lambda x: int(os.path.splitext(x)[0]))\n",
    "\n",
    "    # Check if files exist\n",
    "    if not image_files:\n",
    "        print(\"Error: No images found in the 'images' folder\")\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    if not mask_files:\n",
    "        print(\"Error: No masks found in the 'masks' folder\")\n",
    "        return np.array([]), np.array([])\n",
    "        \n",
    "    # Load images and masks\n",
    "    for img_file, mask_file in zip(image_files, mask_files):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "        img = load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "        mask = load_img(mask_path, target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode=\"grayscale\")\n",
    "\n",
    "        # Convert to arrays and normalize\n",
    "        img_array = img_to_array(img) / 255.0\n",
    "        mask_array = img_to_array(mask) / 255.0\n",
    "\n",
    "        images.append(img_array)\n",
    "        masks.append(mask_array)\n",
    "\n",
    "    return np.array(images), np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a91d1b-ec41-4793-abf6-6eedba4c2044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a prediction array into a binary mask using a threshold.\n",
    "# Pixels greater than 'th' are set to 1, and the rest to 0.\n",
    "def convert_to_binary(predictions, th):\n",
    "    predictions = np.array(predictions) \n",
    "    binary_predictions = (predictions > th).astype(np.uint8)  \n",
    "    return binary_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bafc62c-b06e-49b2-b95c-0427b82c5b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Dice coefficient, a metric for evaluating segmentation accuracy.\n",
    "# It measures the overlap between the predicted and ground truth masks.\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    y_true_f = y_true.flatten()  \n",
    "    y_pred_f = y_pred.flatten()  \n",
    "    intersection = np.sum(y_true_f * y_pred_f)  \n",
    "    dice = (2. * intersection) / (np.sum(y_true_f) + np.sum(y_pred_f))  # Dice formula\n",
    "    return dice  # Return the Dice coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d40a53-6c52-4eaf-8836-192373a783f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data generator using TensorFlow's Dataset API.\n",
    "# This function takes image and mask arrays, shuffles them, \n",
    "# groups them into batches, and enables infinite iteration.\n",
    "\n",
    "def data_generator(images, masks, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, masks)) \n",
    "    dataset = dataset.shuffle(buffer_size=100).batch(batch_size).repeat()  \n",
    "    return dataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28e2c97e-5108-4c7b-bd2a-c80f3cfc81c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the Mean Surface Distance (MSD), which measures the average difference \n",
    "# between the contours of the ground truth segmentation and the predicted segmentation.\n",
    "def mean_surface_distance(y_true, y_pred, th):\n",
    "    y_pred_binary = convert_to_binary(y_pred, th)\n",
    "    y_true_binary = convert_to_binary(y_true, th)\n",
    "    \n",
    "    # Find the contours of the segmentations\n",
    "    contours_true = measure.find_contours(y_true_binary, level=0.5)\n",
    "    contours_pred = measure.find_contours(y_pred_binary, level=0.5)\n",
    "    \n",
    "    if len(contours_true) == 0 or len(contours_pred) == 0:\n",
    "        return float('inf')  # Returns infinity if no contours are detected\n",
    "    \n",
    "    distances = []\n",
    "    \n",
    "    # Compute the minimum distance from each point in the ground truth contour to the predicted contour\n",
    "    for contour_true in contours_true:\n",
    "        distances.extend(np.min(cdist(contour_true, np.vstack(contours_pred), metric='euclidean'), axis=1))\n",
    "    \n",
    "    # Compute the minimum distance from each point in the predicted contour to the ground truth contour\n",
    "    for contour_pred in contours_pred:\n",
    "        distances.extend(np.min(cdist(contour_pred, np.vstack(contours_true), metric='euclidean'), axis=1))\n",
    "    \n",
    "    return np.mean(distances) if distances else float('inf')  # Returns the average of the distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ad32fe4-dad6-445e-93f0-811e077f79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_AEr(pred_mask, true_mask, pixel_size):\n",
    "    \"\"\"\n",
    "    Computes the Absolute Error (AEr) between a predicted segmentation mask and the ground truth.\n",
    "\n",
    "    Parameters:\n",
    "    - pred_mask (numpy array): The predicted binary segmentation mask.\n",
    "    - true_mask (numpy array): The ground truth binary segmentation mask.\n",
    "    - pixel_size (float): The physical size of a pixel, used for area calculation.\n",
    "\n",
    "    Returns:\n",
    "    - AEr (float): The absolute error in terms of area.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to boolean arrays for logical operations\n",
    "    pred_mask = np.array(pred_mask, dtype=bool)\n",
    "    true_mask = np.array(true_mask, dtype=bool)\n",
    "    \n",
    "    # False positives: Pixels predicted as 1 but should be 0\n",
    "    false_positives = np.sum(pred_mask & ~true_mask)\n",
    "    \n",
    "    # False negatives: Pixels predicted as 0 but should be 1\n",
    "    false_negatives = np.sum(~pred_mask & true_mask)\n",
    "    \n",
    "    # Compute AEr\n",
    "    AEr = pixel_size * (false_positives + false_negatives)\n",
    "    \n",
    "    return AEr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "176f88b1-0771-41df-8a2f-d9ecb54a090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valuates the Absolute Error (AEr) over a dataset using a model's predictions.\n",
    "def evaluate_AEr(generator, num_steps, th, pixel_size):\n",
    "    \n",
    "    AEr_values = []\n",
    "    iterator = iter(generator)\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        images, masks = next(iterator)\n",
    "        \n",
    "        # Ensure images and masks are numpy arrays\n",
    "        images = np.array(images)\n",
    "        masks = np.array(masks)\n",
    "        \n",
    "        # Perform model predictions\n",
    "        predictions = model.predict(images)\n",
    "        \n",
    "        for i in range(images.shape[0]):\n",
    "            y_true = np.squeeze(masks[i]).astype(np.float32)\n",
    "            y_pred = np.squeeze(predictions[i]).astype(np.float32)\n",
    "            \n",
    "            # Convert prediction to binary using the given threshold\n",
    "            y_pred_binary = convert_to_binary(y_pred, th)\n",
    "            \n",
    "            # Ignore images with completely black segmentations\n",
    "            if np.sum(y_pred_binary) > 0:\n",
    "                # Compute Absolute Error (AEr)\n",
    "                AEr_value = calculate_AEr(y_pred_binary, y_true, pixel_size)\n",
    "                AEr_values.append(AEr_value)\n",
    "    \n",
    "    # Compute the mean AEr\n",
    "    mean_AEr = np.mean(AEr_values) if AEr_values else float('inf')\n",
    "    \n",
    "    return mean_AEr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57e40dc8-5829-4ae6-b12c-ca97bd9d200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes a confidence interval using the bootstrap resampling method.\n",
    "# Generates multiple bootstrap samples, computes their means, and determines the confidence interval based on percentiles.\n",
    "def bootstrap_ci(data, num_samples=1000, confidence=0.95):\n",
    "\n",
    "    data = np.array(data)\n",
    "    sample_means = []\n",
    "\n",
    "    # Generate bootstrap samples and compute the mean for each sample\n",
    "    for _ in range(num_samples):\n",
    "        sample = np.random.choice(data, size=len(data), replace=True)  # Resampling with replacement\n",
    "        sample_means.append(np.mean(sample))\n",
    "\n",
    "    # Compute percentiles to obtain the confidence interval\n",
    "    lower_bound = np.percentile(sample_means, (1 - confidence) / 2 * 100)\n",
    "    upper_bound = np.percentile(sample_means, (1 + confidence) / 2 * 100)\n",
    "    mean = np.mean(sample_means)\n",
    "\n",
    "    return mean, lower_bound, upper_bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4efb4533-79ba-41f5-a354-496d84dc73fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate segmentation performance using the Dice coefficient.\n",
    "# Iterates through a dataset, computes predictions, and calculates Dice scores.\n",
    "def evaluate_metrics(generator, num_steps, th):\n",
    "    dice_scores = [] \n",
    "    \n",
    "    iterator = iter(generator)  # Convert generator to iterator\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        images, masks = next(iterator)  # Get a batch of images and masks\n",
    "        predictions = model.predict(images)  # Generate predictions\n",
    "        \n",
    "        for i in range(images.shape[0]):\n",
    "            y_true = masks[i].numpy().astype(np.float32) \n",
    "            y_pred = predictions[i].astype(np.float32)  \n",
    "\n",
    "            assert y_true.shape == y_pred.shape, f\"Shape mismatch: {y_true.shape} vs {y_pred.shape}\"\n",
    "\n",
    "            y_pred_binary = (y_pred > th).astype(np.uint8)  # Apply threshold to get binary mask\n",
    "\n",
    "            if np.sum(y_pred_binary) > 0:  # Only compute Dice if segmentation exists\n",
    "                dice = dice_coefficient(y_true, y_pred_binary)\n",
    "                dice_scores.append(dice)\n",
    "    \n",
    "    mean_dice, lower_dice, upper_dice =bootstrap_ci(dice_scores)  # Compute mean Dice coefficient \n",
    "    \n",
    "    return mean_dice, lower_dice, upper_dice # Return the average Dice score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff93cecb-6f95-4969-8e35-bc85242459ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_additional_metrics(generator, num_steps, th):\n",
    "    \n",
    "    msd_values = []\n",
    "    \n",
    "    iterator = iter(generator)\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        images, masks = next(iterator)\n",
    "        predictions = model.predict(images)\n",
    "        \n",
    "        for i in range(images.shape[0]):\n",
    "            y_true = np.squeeze(masks[i]).astype(np.float32)\n",
    "            y_pred = np.squeeze(predictions[i]).astype(np.float32)\n",
    "            \n",
    "            # Convert prediction to binary\n",
    "            y_pred_binary = convert_to_binary(y_pred, th)\n",
    "            \n",
    "            # Ignore images without segmentation\n",
    "            if np.sum(y_pred_binary) > 0:\n",
    "                msd = mean_surface_distance(y_pred_binary, y_true, th)  # Ensure this function is defined\n",
    "                msd_values.append(msd)\n",
    "    \n",
    "    return bootstrap_ci(msd_values)\n",
    "\n",
    "# Evaluates Area Error Rate (AEr) with confidence intervals.\n",
    "def evaluate_AEr(generator, num_steps, th, pixel_size):\n",
    "\n",
    "    AEr_values = []\n",
    "    \n",
    "    iterator = iter(generator)\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        images, masks = next(iterator)\n",
    "        predictions = model.predict(images)\n",
    "        \n",
    "        for i in range(images.shape[0]):\n",
    "            y_true = np.squeeze(masks[i]).astype(np.float32)\n",
    "            y_pred = np.squeeze(predictions[i]).astype(np.float32)\n",
    "            \n",
    "            # Convert prediction to binary\n",
    "            y_pred_binary = convert_to_binary(y_pred, th)\n",
    "            \n",
    "            # Ignore images without segmentation\n",
    "            if np.sum(y_pred_binary) > 0:\n",
    "                AEr = calculate_AEr(y_pred_binary, y_true, pixel_size)\n",
    "                AEr_values.append(AEr)\n",
    "    \n",
    "    return bootstrap_ci(AEr_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b4d2e3-aee3-401d-80a0-fbf6463f1b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"C:\\Users\\Mafe Valenzuela\\Documents\\Cps\\01\\SegmentaciÃ³n\\train\"\n",
    "X_train, y_train = load_images_and_masks_from_directory(train_dir)\n",
    "\n",
    "validation_dir = r\"C:\\Users\\Mafe Valenzuela\\Documents\\Cps\\01\\SegmentaciÃ³n\\val\"\n",
    "X_val, y_val = load_images_and_masks_from_directory(validation_dir)\n",
    "\n",
    "test_dir = r\"C:\\Users\\Mafe Valenzuela\\Documents\\Cps\\01\\SegmentaciÃ³n\\test\"\n",
    "X_test, y_test = load_images_and_masks_from_directory(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efdc2d90-168a-4b8d-a17a-f85a1ccd96d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "pixel_size = 0.16\n",
    "th=0.45\n",
    "\n",
    "train_gen = data_generator(X_train, y_train, BATCH_SIZE)\n",
    "val_gen = data_generator(X_val, y_val, BATCH_SIZE)\n",
    "test_gen = data_generator(X_test, y_test, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddafa54d-845e-44eb-9e64-14c2004d2b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = len(X_train)//BATCH_SIZE\n",
    "val_steps = len(X_val)//BATCH_SIZE\n",
    "test_steps = len(X_test)//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851d1847-b5bb-4521-8972-25a98f9072ec",
   "metadata": {},
   "source": [
    "*CÃ¡lculo de resultados*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73c3fd1e-7e56-4a20-ad2e-d0aeaf559894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Coeficiente de Dice train (95% IC): 0.8747 (0.8616, 0.8858)\n",
      "Mean Surface Distance train (95% IC): 6.6423 (6.0972, 7.1998)\n",
      "Ãrea Error Rate train (95% IC): 472.6511 (438.5240, 506.6298) mmÂ²\n"
     ]
    }
   ],
   "source": [
    "(dice_mean, dice_lower, dice_upper) = evaluate_metrics(train_gen, train_steps, th)\n",
    "(msd_mean, msd_lower, msd_upper) = evaluate_additional_metrics(train_gen, train_steps, th)\n",
    "(aer_mean, aer_lower, aer_upper) = evaluate_AEr(train_gen, train_steps, th, pixel_size)\n",
    "\n",
    "print(f\"Coeficiente de Dice train (95% IC): {dice_mean:.4f} ({dice_lower:.4f}, {dice_upper:.4f})\")\n",
    "print(f\"Mean Surface Distance train (95% IC): {msd_mean:.4f} ({msd_lower:.4f}, {msd_upper:.4f})\")\n",
    "print(f\"Ãrea Error Rate train (95% IC): {aer_mean:.4f} ({aer_lower:.4f}, {aer_upper:.4f}) mmÂ²\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd4743d4-ff2e-4266-b6ca-1498f784462e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Coeficiente de Dice validacion (95% IC): 0.8418 (0.7955, 0.8781)\n",
      "Mean Surface Distance validacion (95% IC): 8.2562 (6.7660, 10.0016)\n",
      "Ãrea Error Rate validacion (95% IC): 567.7764 (478.2659, 668.5594) mmÂ²\n"
     ]
    }
   ],
   "source": [
    "(dice_mean, dice_lower, dice_upper) = evaluate_metrics(val_gen, val_steps, th)\n",
    "(msd_mean, msd_lower, msd_upper) = evaluate_additional_metrics(val_gen, val_steps, th)\n",
    "(aer_mean, aer_lower, aer_upper) = evaluate_AEr(val_gen, val_steps, th, pixel_size)\n",
    "\n",
    "print(f\"Coeficiente de Dice validacion (95% IC): {dice_mean:.4f} ({dice_lower:.4f}, {dice_upper:.4f})\")\n",
    "print(f\"Mean Surface Distance validacion (95% IC): {msd_mean:.4f} ({msd_lower:.4f}, {msd_upper:.4f})\")\n",
    "print(f\"Ãrea Error Rate validacion (95% IC): {aer_mean:.4f} ({aer_lower:.4f}, {aer_upper:.4f}) mmÂ²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21e453f0-c433-4184-86bf-94d1fdc03ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Coeficiente de Dice test (95% IC): 0.8374 (0.7808, 0.8707)\n",
      "Mean Surface Distance test (95% IC): 7.2220 (6.3881, 8.1793)\n",
      "Ãrea Error Rate test (95% IC): 520.8581 (457.7123, 591.7677) mmÂ²\n"
     ]
    }
   ],
   "source": [
    "(dice_mean, dice_lower, dice_upper) = evaluate_metrics(test_gen, test_steps, th)\n",
    "(msd_mean, msd_lower, msd_upper) = evaluate_additional_metrics(test_gen, test_steps, th)\n",
    "(aer_mean, aer_lower, aer_upper) = evaluate_AEr(test_gen, test_steps, th, pixel_size)\n",
    "\n",
    "print(f\"Coeficiente de Dice test (95% IC): {dice_mean:.4f} ({dice_lower:.4f}, {dice_upper:.4f})\")\n",
    "print(f\"Mean Surface Distance test (95% IC): {msd_mean:.4f} ({msd_lower:.4f}, {msd_upper:.4f})\")\n",
    "print(f\"Ãrea Error Rate test (95% IC): {aer_mean:.4f} ({aer_lower:.4f}, {aer_upper:.4f}) mmÂ²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df765b9e-3fff-4602-a3e9-4b913143b4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
